{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729a9879",
   "metadata": {},
   "source": [
    "## Q2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d1d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "187601bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_data = pd.read_csv(r'C:\\Users\\ABC\\Desktop\\BAI\\BAI-S6\\RS\\Assignments\\ml-latest-small\\ratings.csv')\n",
    "movies_data = pd.read_csv(r'C:\\Users\\ABC\\Desktop\\BAI\\BAI-S6\\RS\\Assignments\\ml-latest-small\\movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c833971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing mean ratings for each user\n",
    "user_ratings_mean = np.nanmean(ratings_data.pivot(index='userId', columns='movieId', values='rating'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5652e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centering the ratings matrix\n",
    "ratings_data_centered = ratings_data.pivot(index='userId', columns='movieId', values='rating') - user_ratings_mean[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3de4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing cosine similarity\n",
    "user_similarity_matrix = cosine_similarity(ratings_data_centered.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cd8cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_users(user_id, k=5):\n",
    "    user_similarity = user_similarity_matrix[user_id]\n",
    "    similar_user_indices = user_similarity.argsort()[::-1][1:k+1] # Sort: descending. returning indices of top 5\n",
    "    return similar_user_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3613180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id, movie_id, k=5):\n",
    "    similar_user_indices = get_similar_users(user_id, k=k)\n",
    "    similar_user_ratings = ratings_data_centered.loc[similar_user_indices, movie_id].dropna()\n",
    "    if len(similar_user_ratings) == 0:\n",
    "        return user_ratings_mean[user_id]\n",
    "    else:\n",
    "        similar_user_mean_rating = np.nanmean(similar_user_ratings)\n",
    "        user_rating = ratings_data_centered.loc[user_id, movie_id]\n",
    "        if np.isnan(user_rating):\n",
    "            predicted_rating = similar_user_mean_rating + user_ratings_mean[user_id]\n",
    "        else:\n",
    "            predicted_rating = similar_user_mean_rating + user_rating\n",
    "        # Clip the predicted rating to the range of 0 to 5 so that the rating does not go out of bounds\n",
    "        predicted_rating = max(0, min(predicted_rating, 5))\n",
    "        return predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d7ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(user_id, N=5, k=5):\n",
    "    user_rated_movies = ratings_data.loc[ratings_data['userId'] == user_id, 'movieId']\n",
    "    unrated_movies = set(ratings_data['movieId']) - set(user_rated_movies)\n",
    "    predicted_ratings = [(movie_id, predict_rating(user_id, movie_id, k=k)) for movie_id in unrated_movies]\n",
    "    predicted_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_N_recommendations = predicted_ratings[:N]\n",
    "    top_N_recommendation_titles = [movies_data.loc[movies_data['movieId'] == movie_id, 'title'].iloc[0] for movie_id, rating in top_N_recommendations]\n",
    "    return list(zip(top_N_recommendation_titles, [rating for movie_id, rating in top_N_recommendations]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "700d10d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter user ID: 1\n",
      "Enter the name of the movie: Toy Story (1995)\n",
      "Top 5 movie recommendations for user 1 based on Toy Story (1995):\n",
      "1. Happy Gilmore (1996) (predicted rating: 5.00)\n",
      "2. Apollo 13 (1995) (predicted rating: 5.00)\n",
      "3. Hackers (1995) (predicted rating: 5.00)\n",
      "4. Mallrats (1995) (predicted rating: 5.00)\n",
      "5. Hoop Dreams (1994) (predicted rating: 5.00)\n"
     ]
    }
   ],
   "source": [
    "# Test the recommender system (done, now doing it properly by prompting user to input movie name)\n",
    "# user_id = 1\n",
    "# movie_name = \"Toy Story (1995)\"\n",
    "user_id = int(input(\"Enter user ID: \"))\n",
    "movie_name = input(\"Enter the name of the movie: \")\n",
    "movie_id = movies_data.loc[movies_data['title'] == movie_name, 'movieId'].iloc[0]\n",
    "recommended_movies = get_top_recommendations(user_id, N=5, k=5)\n",
    "\n",
    "print(f\"Top 5 movie recommendations for user {user_id} based on {movie_name}:\")\n",
    "for i, (title, rating) in enumerate(recommended_movies):\n",
    "    print(f\"{i+1}. {title} (predicted rating: {rating:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d1e77d",
   "metadata": {},
   "source": [
    "## Q2(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a8499b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e76e460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ABC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d53ad863",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df = pd.read_csv(r'C:\\Users\\ABC\\Desktop\\BAI\\BAI-S6\\RS\\Assignments\\ml-latest-small\\links.csv')\n",
    "tags_df = pd.read_csv(r'C:\\Users\\ABC\\Desktop\\BAI\\BAI-S6\\RS\\Assignments\\ml-latest-small\\tags.csv')\n",
    "movies_df = pd.read_csv(r'C:\\Users\\ABC\\Desktop\\BAI\\BAI-S6\\RS\\Assignments\\ml-latest-small\\movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eac4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pd.merge(movies_df, tags_df, on='movieId')\n",
    "movie_data.drop(['userId', 'timestamp'], axis=1, inplace=True)\n",
    "movie_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6598891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = [stemmer.stem(token) for token in tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cd0f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_vectorizer = CountVectorizer(tokenizer=tokenize, token_pattern=None)\n",
    "genres_bow = genres_vectorizer.fit_transform(movie_data['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b4e2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(genres_bow) # bow = bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e761b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_movies(movie_title):\n",
    "    movie_idx = movies_df[movies_df['title'] == movie_title].index[0]\n",
    "    similar_movies = list(enumerate(cosine_sim[movie_idx]))\n",
    "    similar_movies = sorted(similar_movies, key=lambda x: x[1], reverse=True)\n",
    "    top_similar_movies = similar_movies[1:4]\n",
    "    similar_movie_indices = [i[0] for i in top_similar_movies]\n",
    "    return movies_df.iloc[similar_movie_indices]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "537873fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the movie: Waiting to Exhale (1995)\n",
      "Recommended movies based on genres:\n",
      "Father of the Bride Part II (1995)\n",
      "Heat (1995)\n",
      "Sabrina (1995)\n"
     ]
    }
   ],
   "source": [
    "movie_name = input(\"Enter the name of the movie: \")\n",
    "similar_movies = get_similar_movies(movie_name)\n",
    "\n",
    "print(\"Recommended movies based on genres:\")\n",
    "for movie in similar_movies:\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1aabae",
   "metadata": {},
   "source": [
    "### Manahil Fatima Anwar\n",
    "### 20K-0134\n",
    "### BAI-6A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
